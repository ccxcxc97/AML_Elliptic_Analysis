{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-21T07:58:35.951835Z",
     "start_time": "2026-01-21T07:58:15.441878Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# 1. åŠ è½½æ¸…æ´—åçš„æ•°æ®\n",
    "# ==========================================\n",
    "print(\">>> 1. åŠ è½½æ•°æ®...\")\n",
    "# è¯»å–ä¸Šä¸€é˜¶æ®µæ¸…æ´—å¥½çš„æ•°æ®\n",
    "df = pd.read_csv('../data/processed/elliptic_cleaned.csv')\n",
    "\n",
    "# è¯»å–åŸå§‹è¾¹åˆ—è¡¨ (ç”¨æ¥æ„å»ºå›¾)\n",
    "# æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬åªä¿ç•™è¿æ¥\"æ¸…æ´—åå­˜åœ¨çš„èŠ‚ç‚¹\"çš„è¾¹\n",
    "edges_raw = pd.read_csv('../data/raw/elliptic_txs_edgelist.csv')\n",
    "\n",
    "print(f\"åŸå§‹èŠ‚ç‚¹æ•°: {len(df)}\")\n",
    "print(f\"åŸå§‹è¾¹æ•°: {len(edges_raw)}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. èŠ‚ç‚¹é‡æ˜ å°„ (Re-indexing) [å…³é”®æ­¥éª¤]\n",
    "# ==========================================\n",
    "# PyG è¦æ±‚èŠ‚ç‚¹ç´¢å¼•å¿…é¡»æ˜¯ 0 åˆ° N-1 çš„è¿ç»­æ•´æ•°ã€‚\n",
    "# ä½†åŸå§‹æ•°æ®çš„ txId æ˜¯éšæœºçš„å¤§æ•´æ•°ï¼ˆå¦‚ 355110272ï¼‰ã€‚\n",
    "# æˆ‘ä»¬éœ€è¦å»ºç«‹ä¸€ä¸ªæ˜ å°„ï¼š raw_id -> new_id (0, 1, 2...)\n",
    "\n",
    "print(\"\\n>>> 2. æ‰§è¡ŒèŠ‚ç‚¹é‡æ˜ å°„...\")\n",
    "\n",
    "# 1. ç»™æ¯ä¸ªèŠ‚ç‚¹åˆ†é…ä¸€ä¸ªæ–°çš„ç´¢å¼• (0, 1, 2, ..., N-1)\n",
    "# é‡ç½®ç´¢å¼•ï¼Œè®© DataFrame çš„ index å˜æˆ 0..N-1\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# åˆ›å»ºæ˜ å°„å­—å…¸: {åŸå§‹txId : æ–°ç´¢å¼•Index}\n",
    "id_map = {row['txId']: i for i, row in df.iterrows()}\n",
    "\n",
    "# 2. è¿‡æ»¤è¾¹åˆ—è¡¨\n",
    "# åªä¿ç•™ä¸¤ç«¯éƒ½åœ¨æˆ‘ä»¬ df é‡Œçš„è¾¹\n",
    "edges_mask = edges_raw['txId1'].isin(df['txId']) & edges_raw['txId2'].isin(df['txId'])\n",
    "edges_clean = edges_raw[edges_mask].copy()\n",
    "\n",
    "# 3. å°†è¾¹åˆ—è¡¨é‡Œçš„ txId æ›¿æ¢ä¸ºæ–°ç´¢å¼•\n",
    "edges_clean['source_node'] = edges_clean['txId1'].map(id_map)\n",
    "edges_clean['target_node'] = edges_clean['txId2'].map(id_map)\n",
    "\n",
    "print(f\"é‡æ˜ å°„å®Œæˆã€‚æœ‰æ•ˆè¾¹æ•°é‡: {len(edges_clean)}\")\n",
    "\n",
    "# ==========================================\n",
    "# ğŸ” è°ƒè¯•ä¸ä¿®å¤ï¼šæ£€æŸ¥åˆ—å\n",
    "# ==========================================\n",
    "print(\"å½“å‰çš„æ‰€æœ‰åˆ—å:\", df.columns.tolist()[:10], \"...\") # åªæ‰“å°å‰10ä¸ªçœ‹çœ‹\n",
    "\n",
    "# 1. å°è¯•è‡ªåŠ¨ä¿®å¤å¸¸è§çš„åˆ—åå˜ä½“\n",
    "possible_names = ['Time step', 'time_step', 'timestep', '1', 1] # '1' æ˜¯åŸå§‹æ•°æ®ä¸­çš„å¸¸è§åˆ—å\n",
    "\n",
    "found_col = None\n",
    "for name in possible_names:\n",
    "    if name in df.columns:\n",
    "        found_col = name\n",
    "        break\n",
    "\n",
    "if found_col:\n",
    "    print(f\"âœ… æ‰¾åˆ°äº†æ—¶é—´åˆ—ï¼Œå½“å‰åç§°ä¸º: '{found_col}'\")\n",
    "    if found_col != 'Time step':\n",
    "        print(f\"ğŸ”„ æ­£åœ¨å°†å…¶é‡å‘½åä¸º 'Time step'...\")\n",
    "        df.rename(columns={found_col: 'Time step'}, inplace=True)\n",
    "else:\n",
    "    # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œå¯èƒ½åœ¨æŸä¸ªä½ç½®ï¼ˆé€šå¸¸æ˜¯ç¬¬äºŒåˆ—ï¼‰\n",
    "    # ä¹Ÿå°±æ˜¯ features.csv çš„ç¬¬2åˆ— (ç´¢å¼•ä¸º1)\n",
    "    print(\"âš ï¸ æœªæŒ‰åç§°æ‰¾åˆ°æ—¶é—´åˆ—ï¼Œå°è¯•æŒ‰ä½ç½®æ¨æ–­...\")\n",
    "    # å‡è®¾ 'class' å’Œ 'txId' å­˜åœ¨ï¼Œå‰©ä¸‹çš„ç¬¬ä¸€åˆ—å¯èƒ½æ˜¯æ—¶é—´ï¼Ÿ\n",
    "    # æˆ–è€…ç›´æ¥çœ‹ç¬¬2åˆ—ï¼ˆå¦‚æœç¬¬1åˆ—æ˜¯txIdï¼‰\n",
    "    print(\"ç¬¬2åˆ—çš„æ•°æ®æ ·ä¾‹:\", df.iloc[:, 1].head().values)\n",
    "\n",
    "    # å¼ºåˆ¶é‡å‘½åç¬¬2åˆ— (éå¸¸è§„æ‰‹æ®µï¼Œæ…ç”¨ï¼Œè¯·å…ˆç¡®è®¤ä¸Šé¢çš„æ‰“å°ç»“æœ)\n",
    "    # col_name_at_idx_1 = df.columns[1]\n",
    "    # df.rename(columns={col_name_at_idx_1: 'Time step'}, inplace=True)\n",
    "\n",
    "print(\"å½“å‰åˆ—åæ£€æŸ¥å®Œæ¯•ã€‚\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. æ—¶é—´åˆ‡åˆ† (Temporal Split)\n",
    "# ==========================================\n",
    "# æ ¹æ® Elliptic è®ºæ–‡æ ‡å‡†ï¼š\n",
    "# è®­ç»ƒé›†: Time step 1 - 34\n",
    "# æµ‹è¯•é›†: Time step 35 - 49\n",
    "\n",
    "print(\"\\n>>> 3. åˆ›å»ºæ—¶é—´åˆ‡åˆ†æ©ç ...\")\n",
    "\n",
    "# ç¡®ä¿ class åˆ—æ˜¯æ•´æ•° (1=Illicit, 2=Licit)\n",
    "# è¿™é‡Œæˆ‘ä»¬æŠŠå®ƒä»¬è½¬ä¸º 0 å’Œ 1ï¼Œç¬¦åˆ PyTorch çš„äºŒåˆ†ç±»ä¹ æƒ¯\n",
    "# é€šå¸¸å®šä¹‰: 1=Illicit (æ­£æ ·æœ¬), 0=Licit (è´Ÿæ ·æœ¬)\n",
    "class_map = {1: 1, 2: 0, '1': 1, '2': 0}\n",
    "df['label'] = df['class'].map(class_map)\n",
    "\n",
    "# å®šä¹‰åˆ‡åˆ†ç‚¹\n",
    "split_timestep = 34\n",
    "\n",
    "# åˆ›å»ºåˆ—æ¥æ ‡è®°æ•°æ®é›†å½’å± (æ–¹ä¾¿åŸºå‡†æ¨¡å‹ä½¿ç”¨)\n",
    "df['split'] = 'train'\n",
    "df.loc[df['Time step'] > split_timestep, 'split'] = 'test'\n",
    "\n",
    "print(\"è®­ç»ƒé›†/æµ‹è¯•é›†åˆ†å¸ƒ:\")\n",
    "print(df['split'].value_counts())\n",
    "\n",
    "# ==========================================\n",
    "# 4. æ„å»º PyG Data å¯¹è±¡ (ä¿®å¤ç‰ˆ)\n",
    "# ==========================================\n",
    "print(\">>> 4. æ„å»º PyG Data å¯¹è±¡ (Safe Mode)...\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# A. ç‰¹å¾çŸ©é˜µ (x) - å¼ºåŠ›æ¸…æ´—é€»è¾‘\n",
    "# -------------------------------------------------------\n",
    "\n",
    "# 1. é¦–å…ˆï¼Œåªé€‰æ‹©æ•°å€¼ç±»å‹çš„åˆ— (æ’é™¤æ‰€æœ‰å­—ç¬¦ä¸²åˆ—)\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# 2. å®šä¹‰å¿…é¡»è¦å‰”é™¤çš„éç‰¹å¾åˆ— (ID, æ—¶é—´, æ ‡ç­¾)\n",
    "# æ³¨æ„ï¼šæˆ‘ä»¬è¦å‰”é™¤åŸå§‹çš„ 'class' (å¦‚æœæ˜¯æ•°å­—) å’Œæˆ‘ä»¬ç”Ÿæˆçš„ 'label'\n",
    "exclude_cols = ['txId', 'Time step', 'class', 'label']\n",
    "\n",
    "# 3. è®¡ç®—æœ€ç»ˆçš„ç‰¹å¾åˆ—å\n",
    "# (åœ¨ numeric_df çš„åˆ—ä¸­ï¼Œå»é™¤ exclude_cols)\n",
    "feature_cols = [c for c in numeric_df.columns if c not in exclude_cols]\n",
    "\n",
    "# --- [è°ƒè¯•] æ£€æŸ¥ä¸€ä¸‹æ˜¯ä¸æ˜¯æœ‰åˆ—è¢«è¯¯åˆ æˆ–é—æ¼ ---\n",
    "print(f\"åŸå§‹ DataFrame åˆ—æ•°: {len(df.columns)}\")\n",
    "print(f\"æ•°å€¼å‹ DataFrame åˆ—æ•°: {len(numeric_df.columns)}\")\n",
    "print(f\"æœ€ç»ˆç‰¹å¾æ•°é‡: {len(feature_cols)}\")\n",
    "\n",
    "# å¦‚æœç‰¹å¾æ•°å¼‚å¸¸å°‘ (æ¯”å¦‚ä¸º0)ï¼ŒæŠ¥é”™æé†’\n",
    "if len(feature_cols) == 0:\n",
    "    raise ValueError(\"é”™è¯¯ï¼šæ‰¾ä¸åˆ°ä»»ä½•ç‰¹å¾åˆ—ï¼è¯·æ£€æŸ¥ 'exclude_cols' è®¾ç½®æˆ–æ•°æ®ç±»å‹ã€‚\")\n",
    "\n",
    "# --- [å…³é”®æ­¥éª¤] è½¬æ¢ä¸º Tensor ---\n",
    "# values å¯èƒ½ä¼šå› ä¸ºå†…å­˜ä¸è¿ç»­æŠ¥é”™ï¼ŒåŠ ä¸Š .copy()\n",
    "x = torch.tensor(numeric_df[feature_cols].values, dtype=torch.float)\n",
    "\n",
    "print(f\"âœ… ç‰¹å¾çŸ©é˜µ x æ„å»ºæˆåŠŸ! Shape: {x.shape}\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# B. è¾¹ç´¢å¼• (edge_index)\n",
    "# -------------------------------------------------------\n",
    "# ç¡®ä¿è¾¹ç´¢å¼•ä¹Ÿæ˜¯ Long ç±»å‹\n",
    "edge_index = torch.tensor(edges_clean[['source_node', 'target_node']].values, dtype=torch.long)\n",
    "edge_index = edge_index.t().contiguous() # è½¬ç½®ä¸º shape [2, E]\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# C. æ ‡ç­¾ (y)\n",
    "# -------------------------------------------------------\n",
    "y = torch.tensor(df['label'].values, dtype=torch.long)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# D. æ©ç  (Masks)\n",
    "# -------------------------------------------------------\n",
    "train_mask = torch.tensor(df['Time step'] <= split_timestep, dtype=torch.bool)\n",
    "test_mask = torch.tensor(df['Time step'] > split_timestep, dtype=torch.bool)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# E. ç»„è£… Data å¯¹è±¡\n",
    "# -------------------------------------------------------\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "data.train_mask = train_mask\n",
    "data.test_mask = test_mask\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(\"PyG æ•°æ®å¯¹è±¡ä¿¡æ¯:\")\n",
    "print(data)\n",
    "print(f\"ç‰¹å¾ç»´åº¦: {data.num_features}\")\n",
    "print(f\"æ˜¯å¦ä¸ºæ— å‘å›¾: {data.is_undirected()}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# ==========================================\n",
    "# 5. ä¿å­˜æ–‡ä»¶ (é¡ºä¾¿åœ¨è¿™é‡Œæ‰§è¡Œäº†)\n",
    "# ==========================================\n",
    "import os\n",
    "output_dir = '../data/processed/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# ä¿å­˜ .pt æ–‡ä»¶\n",
    "torch.save(data, os.path.join(output_dir, 'elliptic_pyg.pt'))\n",
    "print(f\"âœ… GNN æ•°æ®å·²ä¿å­˜: {os.path.join(output_dir, 'elliptic_pyg.pt')}\")\n",
    "\n",
    "# ä¿å­˜ .csv æ–‡ä»¶ (åŒ…å«ç‰¹å¾å’Œsplitæ ‡è®°)\n",
    "# é‡æ–°æŠŠ 'split' åˆ—åŠ å› numeric_df æ–¹ä¾¿ä¿å­˜ (å› ä¸ºåˆšæ‰åªé€‰äº†æ•°å€¼)\n",
    "numeric_df['split'] = df['split']\n",
    "numeric_df['txId'] = df['txId'] # åŠ ä¸ŠIDæ–¹ä¾¿ç´¢å¼•\n",
    "numeric_df['label'] = df['label'] # åŠ ä¸Šlabel\n",
    "\n",
    "# åªä¿å­˜éœ€è¦çš„åˆ—\n",
    "save_cols = ['txId', 'label', 'split'] + feature_cols\n",
    "output_csv_path = os.path.join(output_dir, 'elliptic_benchmark.csv')\n",
    "numeric_df[save_cols].to_csv(output_csv_path, index=False)\n",
    "print(f\"âœ… åŸºå‡†æ¨¡å‹æ•°æ®å·²ä¿å­˜: {output_csv_path}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 1. åŠ è½½æ•°æ®...\n",
      "åŸå§‹èŠ‚ç‚¹æ•°: 46564\n",
      "åŸå§‹è¾¹æ•°: 234355\n",
      "\n",
      ">>> 2. æ‰§è¡ŒèŠ‚ç‚¹é‡æ˜ å°„...\n",
      "é‡æ˜ å°„å®Œæˆã€‚æœ‰æ•ˆè¾¹æ•°é‡: 36624\n",
      "å½“å‰çš„æ‰€æœ‰åˆ—å: ['txId', 'time_step', 'feat_0', 'feat_1', 'feat_2', 'feat_3', 'feat_4', 'feat_5', 'feat_6', 'feat_7'] ...\n",
      "âœ… æ‰¾åˆ°äº†æ—¶é—´åˆ—ï¼Œå½“å‰åç§°ä¸º: 'time_step'\n",
      "ğŸ”„ æ­£åœ¨å°†å…¶é‡å‘½åä¸º 'Time step'...\n",
      "å½“å‰åˆ—åæ£€æŸ¥å®Œæ¯•ã€‚\n",
      "\n",
      ">>> 3. åˆ›å»ºæ—¶é—´åˆ‡åˆ†æ©ç ...\n",
      "è®­ç»ƒé›†/æµ‹è¯•é›†åˆ†å¸ƒ:\n",
      "split\n",
      "train    29894\n",
      "test     16670\n",
      "Name: count, dtype: int64\n",
      ">>> 4. æ„å»º PyG Data å¯¹è±¡ (Safe Mode)...\n",
      "åŸå§‹ DataFrame åˆ—æ•°: 171\n",
      "æ•°å€¼å‹ DataFrame åˆ—æ•°: 169\n",
      "æœ€ç»ˆç‰¹å¾æ•°é‡: 165\n",
      "âœ… ç‰¹å¾çŸ©é˜µ x æ„å»ºæˆåŠŸ! Shape: torch.Size([46564, 165])\n",
      "------------------------------\n",
      "PyG æ•°æ®å¯¹è±¡ä¿¡æ¯:\n",
      "Data(x=[46564, 165], edge_index=[2, 36624], y=[46564], train_mask=[46564], test_mask=[46564])\n",
      "ç‰¹å¾ç»´åº¦: 165\n",
      "æ˜¯å¦ä¸ºæ— å‘å›¾: False\n",
      "------------------------------\n",
      "âœ… GNN æ•°æ®å·²ä¿å­˜: ../data/processed/elliptic_pyg.pt\n",
      "âœ… åŸºå‡†æ¨¡å‹æ•°æ®å·²ä¿å­˜: ../data/processed/elliptic_benchmark.csv\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
